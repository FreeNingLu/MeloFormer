# MeloFormer 研发日记

## 2024-12-01

### 今日工作概要

完成 MeloFormer v0.5.0 版本的代码精简、版本更新和 GitHub 发布。

---

### 1. 代码精简

#### 删除的冗余文件
| 文件/目录 | 原因 |
|-----------|------|
| `_archived/` | 旧代码和文档备份 |
| `valid_midi_files.txt` | 60MB 文件列表，路径依赖本地环境 |
| `test_local.py` | 开发测试脚本 |
| `test_train_flow.py` | 开发测试脚本 |
| `PROJECT_STRUCTURE.md` | 冗余文档 |
| `data/dataset.py` | 未被 train.py 使用的数据集类 |

#### train.py 优化
- 文档字符串从 24 行压缩到 1 行
- 所有 import 语句移至文件顶部
- 删除 4 处重复的 `import json`, `import random`
- 删除 5 处分隔注释块 (`# ========`)

#### data/__init__.py 精简
- 仅导出实际使用的接口：`HIDTokenizerV2`, `TokenInfo`, `Music21ChordDetector`, `get_chord_vocab`
- 保留向后兼容别名

#### 精简效果
| 指标 | 精简前 | 精简后 |
|------|--------|--------|
| 包大小 | ~9MB | 55KB |
| 文件数 | 20+ | 18 |

---

### 2. 版本更新

- `__init__.py`: 版本号 `0.1.0` → `0.5.0`
- `README.md`: 标题改为 `MeloFormer`
- 目录重命名: `hid_museformer_v0.2` → `hid_museformer_v0.5`

---

### 3. GitHub 发布

**仓库地址**: https://github.com/FreeNingLu/MeloFormer

**提交信息**:
```
Initial commit: MeloFormer v0.5.0

HID-based symbolic music generation model with Summary Token + FlexAttention

Features:
- Summary Token mechanism (SS, SR, RS, RR attention phases)
- FlexAttention for efficient sparse attention (PyTorch 2.5+)
- Multi-GPU DDP training support
- Sharded data loading with LRU cache

Model sizes: small(17M), base(85M), large(200M), xlarge(450M)
```

**最终目录结构**:
```
MeloFormer/
├── model/
│   ├── __init__.py
│   ├── attention_flex.py           # RoPE, FlexFCAttentionMask
│   ├── attention_flex_summary.py   # Summary Token 核心实现
│   └── hid_museformer.py           # 主模型
├── data/
│   ├── __init__.py
│   ├── tokenizer_v2.py             # HID Tokenizer
│   ├── midi_to_txt.py              # MIDI → TXT
│   ├── txt_to_midi.py              # TXT → MIDI
│   ├── chord_detector_music21.py   # 和弦检测
│   ├── filter_midi.py              # MIDI 过滤
│   ├── build_vocab_minimal.py      # 词表构建
│   └── vocab_minimal.pkl           # 预构建词表
├── train.py                        # 训练脚本 (单卡/DDP)
├── preprocess_data.py              # 数据预处理
├── generate.py                     # 生成脚本
├── README.md
├── __init__.py
└── .gitignore
```

---

### 4. 模型规格

| Size | Params | Layers | Dim | Heads | FFN |
|------|--------|--------|-----|-------|-----|
| small | 17M | 6 | 256 | 4 | 1408 |
| base | 85M | 12 | 512 | 8 | 2816 |
| large | 200M | 16 | 768 | 12 | 4096 |
| xlarge | 450M | 24 | 1024 | 16 | 5632 |

---

### 5. 核心技术特点

#### Summary Token + FlexAttention
- **SS**: Summary → Summary (粗粒度跨 bar 因果注意力)
- **SR**: Summary ← Regular (信息压缩，每个 Summary 收集对应 bar 的 Regular tokens)
- **RS**: Regular → Summary (远距离上下文，Regular tokens 看历史 Summary)
- **RR**: Regular → Regular (细粒度近距离，同 bar 内全连接)

#### 稀疏策略
- **Bar 级**: 同乐器全连接，跨乐器选择性 (offset ≤ 2 或 4)
- **Token 类型级**: T-T, T-P, P-P, V-V 可见，D 相关隐藏

#### 之前修复的 Bug
- CUDA `indexSelectLargeIndex` 越界错误：通过在 `create_block_masks` 中填充 tensor 到 `seq_len` 解决

---

### 6. 下一步计划

1. 在 H800 服务器上克隆仓库并测试训练
2. 上传预处理好的数据集
3. 启动完整训练

---

### 备注

- 本地打包文件: `~/Desktop/hid_museformer_v0.5.tar.gz` (55KB)
- 后台仍在运行数据预处理和 MIDI 数据集打包任务

---

## 2024-12-01 (续)

### 今日工作概要

完成 MeloFormer v0.8 版本的 FlexAttention + 混合精度 + Gradient Checkpointing 兼容性修复，并在 32GB GPU 上进行验证测试。

---

### 1. FlexAttention + 混合精度兼容性问题

#### 问题描述
FlexAttention 在混合精度 (BF16/FP16) + Gradient Checkpointing 下，反向传播时出现 dtype 不匹配错误：

```
RuntimeError: expected scalar type BFloat16 but found Float
```

**根本原因**: FlexAttention 的 `sdpa_dense_backward` 在反向传播时计算 `softmax_scores` 使用 FP32，但期望 `query.dtype` 匹配。

#### 尝试的修复方案

| 方案 | 描述 | 结果 |
|------|------|------|
| 方案 1 | Checkpoint 中包裹 autocast 上下文 | 失败 |
| 方案 2 | 选择性 checkpoint (只 checkpoint FFN) | 失败 |
| **方案 3** | **强制 FlexAttention 使用 FP32** | **成功** |

#### 最终修复

在 `attention_flex_summary.py` 中，FlexAttention 调用前禁用 autocast 并转换为 FP32：

```python
# === 阶段 1: Summarize (SS + SR) ===
with torch.autocast(device_type='cuda', enabled=False):
    sum_q_fp32 = sum_q.float()
    sum_k_fp32 = sum_k.float()
    sum_v_fp32 = sum_v.float()
    reg_k_fp32 = reg_k.float()
    reg_v_fp32 = reg_v.float()

    cat_k_sum = torch.cat([sum_k_fp32, reg_k_fp32], dim=2)
    cat_v_sum = torch.cat([sum_v_fp32, reg_v_fp32], dim=2)

    sum_attn_out = flex_attention(sum_q_fp32, cat_k_sum, cat_v_sum, block_mask=summarize_block_mask)
    sum_attn_out = sum_attn_out.to(sum_q.dtype)  # 转回原始 dtype
```

**代价**: FlexAttention 使用 FP32 导致显存占用增加约 50%。

---

### 2. 选择性 Gradient Checkpointing

在 `hid_museformer.py` 中实现选择性 checkpoint：
- **Attention 部分**: 正常执行 (不 checkpoint)，避免 FlexAttention dtype 问题
- **FFN 部分**: 使用 checkpoint 节省显存

```python
def _checkpoint_forward(self, layer, sum_x, x, summarize_mask, updating_mask):
    # Attention 部分 - 正常执行
    sum_x, x = layer.attention(sum_x, x, summarize_mask, updating_mask)

    # FFN 部分 - 使用 checkpoint
    def ffn_forward(sum_x, x):
        sum_x = layer._apply_ffn(sum_x, is_summary=True)
        x = layer._apply_ffn(x, is_summary=False)
        return sum_x, x

    sum_x, x = torch.utils.checkpoint.checkpoint(ffn_forward, sum_x, x, use_reentrant=False)
    return sum_x, x
```

---

### 3. 32GB GPU 显存测试

#### 测试结果

| 配置 | seq_len | batch | 显存 | 状态 |
|------|---------|-------|------|------|
| small | 4096 | 2 | ~8 GB | ✓ |
| small | 16384 | 1 | ~20 GB | ✓ |
| small | 24576 | 1 | ~30+ GB | ❌ OOM |
| base | 8192 | 4 | ~32+ GB | ❌ OOM |

#### 32GB GPU 推荐配置

| 模型 | 最大 seq_len | batch | 梯度累积 |
|------|-------------|-------|---------|
| small | 16384-20480 | 1 | 32 |
| base | 8192-10240 | 1 | 32 |

---

### 4. 训练速度测试

**测试配置**: small 模型, seq=4096, batch=2, 32GB GPU

| Epoch | 时间 | Tokens/sec |
|-------|------|------------|
| 1 | 83.5s | ~2,161 (预热) |
| 2 | 37.2s | ~6,465 |
| 3 | 19.5s | ~8,811 |

**稳定吞吐量**: ~7,500 tokens/sec

---

### 5. H800 训练时间估算

基于 32GB GPU 测试数据推算 8×H800 训练 45 万首歌：

| 模型 | 吞吐量 | 1 Epoch | 100 Epochs |
|------|--------|---------|------------|
| small (8×H800) | ~200K tok/s | ~5 小时 | ~3 周 |
| base (8×H800) | ~100K tok/s | ~10 小时 | ~6 周 |
| large (8×H800) | ~60K tok/s | ~17 小时 | ~10 周 |

---

### 6. 版本更新

- **v0.5 → v0.8**:
  - 修复 FlexAttention + 混合精度兼容性
  - 添加选择性 Gradient Checkpointing
  - 添加 FP16 GradScaler 支持
  - 优化训练日志输出

---

### 7. 下一步计划

1. 在 H800 集群上验证多卡 DDP 训练
2. 完成 45 万首歌的数据预处理
3. 启动正式训练 (small 模型先行验证)
4. 考虑是否升级到 PyTorch 2.6 以获得更好的 FlexAttention BF16 支持

---

### 8. 关键文件修改

| 文件 | 修改内容 |
|------|---------|
| `attention_flex_summary.py` | FlexAttention FP32 workaround |
| `hid_museformer.py` | 选择性 Gradient Checkpointing |
| `train.py` | FP16 GradScaler, autocast_dtype 传递 |

---

### 备注

- FlexAttention FP32 是 PyTorch 2.5 的已知限制，未来版本可能修复
- 显存占用比纯 BF16 高约 50%，是当前的权衡方案
- **2024-12-02 的工作已迁移到独立日报**：[研发日记_2024-12-02.md](研发日记_2024-12-02.md)
