# ========================================
# MeloFormer v0.9.2 FIXED - æ¸è¿›å¼åˆ‡æ¢
# æœåŠ¡å™¨å¯åŠ¨å‘½ä»¤
# ========================================

# åœæ­¢æ—§è®­ç»ƒ
pkill -f train.py

# è§£åŽ‹æ–°ç‰ˆæœ¬
cd ~/autodl-tmp
tar -xzf MeloFormer_v0.9.2_FIXED.tar.gz
cd hid_museformer_v0.9

# å¯åŠ¨è®­ç»ƒ
python train.py \
    --model_size small \
    --data_dir ~/autodl-tmp/processed_data \
    --output_dir ~/autodl-tmp/checkpoints \
    --max_seq_len 8192 \
    --batch_size 4 \
    --gradient_accumulation_steps 8 \
    --learning_rate 3e-4 \
    --epochs 100 \
    --num_workers 8 \
    --log_interval 10 \
    --save_interval 5000


# ========================================
# é¢„æœŸè®­ç»ƒè¿‡ç¨‹
# ========================================

# Step 1-50: num_workers=0
# - ç¼–è¯‘å®Œæˆï¼ˆStep 10ï¼‰
# - ç»§ç»­ç”¨å•è¿›ç¨‹åŠ è½½ï¼ˆStep 11-49ï¼‰
# - å†…å­˜å ç”¨: ~50-60GBï¼ˆå®‰å…¨ï¼‰
# - Tokens/s: ~700-1000ï¼ˆæ…¢ä½†å®‰å…¨ï¼‰

# Step 50: åˆ‡æ¢ï¼
============================================================
âœ… FlexAttention ç¼–è¯‘å®Œæˆï¼
ðŸ”„ åˆ‡æ¢ DataLoader: num_workers 0 â†’ 8
============================================================

# Step 51+: num_workers=8
# - 8 ä¸ª worker å¹¶è¡ŒåŠ è½½
# - é€æ­¥å¡«å…… 30 ä¸ªåˆ†ç‰‡ç¼“å­˜
# - å†…å­˜å ç”¨: 60GB â†’ 75GBï¼ˆç¨³å®šï¼‰
# - Tokens/s: 1000 â†’ 6000-7000ï¼ˆå¿«ï¼ï¼‰


# ========================================
# åŽå°è¿è¡Œ
# ========================================

nohup python train.py \
    --model_size small \
    --data_dir ~/autodl-tmp/processed_data \
    --output_dir ~/autodl-tmp/checkpoints \
    --max_seq_len 8192 \
    --batch_size 4 \
    --gradient_accumulation_steps 8 \
    --learning_rate 3e-4 \
    --epochs 100 \
    --num_workers 8 \
    --log_interval 10 \
    --save_interval 5000 > train.log 2>&1 &

# æŸ¥çœ‹æ—¥å¿—
tail -f train.log

# ç›‘æŽ§å†…å­˜
watch -n 1 'free -h && echo "========" && nvidia-smi'
