# ========================================
# MeloFormer v1.0.0 - 三阶段动态优化版
# 服务器启动命令
# ========================================

# 停止旧训练
pkill -f train.py

# 解压新版本
cd ~/autodl-tmp
tar -xzf MeloFormer_v1.0.0.tar.gz
cd hid_museformer_v0.9

# 启动训练（batch_size=6，比 v0.9.2 快 50%）
python train.py \
    --model_size small \
    --data_dir ~/autodl-tmp/processed_data \
    --output_dir ~/autodl-tmp/checkpoints \
    --max_seq_len 8192 \
    --batch_size 6 \
    --gradient_accumulation_steps 8 \
    --learning_rate 3e-4 \
    --epochs 100 \
    --num_workers 8 \
    --log_interval 10 \
    --save_interval 5000


# ========================================
# 预期训练过程
# ========================================

# Phase 1 (Step 1-10): 编译阶段
# - batch_size=1, num_workers=0
# - GPU 显存: ~10GB（非常安全！）
# - 编译 FlexAttention...

# Step 10: 编译完成
============================================================
✅ FlexAttention 编译完成！
📌 Phase 2: 继续用 batch_size=1，等待内存稳定...
============================================================

# Phase 2 (Step 11-50): 内存稳定期
# - batch_size=1, num_workers=0
# - GPU 显存: ~10GB（持续安全）
# - Tokens/s: ~1000-1500（慢但稳定）

# Step 50: 切换！
============================================================
🚀 切换到 Phase 3 (高速训练模式)
📊 batch_size: 1 → 6
👷 num_workers: 0 → 8
⚡ 预期加速: 6.0x
============================================================

# Phase 3 (Step 51+): 高速训练
# - batch_size=6, num_workers=8
# - GPU 显存: ~52GB（留 28GB 余量）
# - Tokens/s: 10000-12000（相比 v0.9.2 提升 50%！）
# - GPU 利用率: 95-100%


# ========================================
# 后台运行
# ========================================

nohup python train.py \
    --model_size small \
    --data_dir ~/autodl-tmp/processed_data \
    --output_dir ~/autodl-tmp/checkpoints \
    --max_seq_len 8192 \
    --batch_size 6 \
    --gradient_accumulation_steps 8 \
    --learning_rate 3e-4 \
    --epochs 100 \
    --num_workers 8 \
    --log_interval 10 \
    --save_interval 5000 > train.log 2>&1 &

# 查看日志
tail -f train.log

# 监控 GPU 和内存
watch -n 1 'nvidia-smi && echo "========" && free -h'


# ========================================
# 性能对比
# ========================================

# v0.9.2:
# - batch_size=4 全程
# - 编译显存: ~40GB (有 OOM 风险)
# - 训练显存: ~40GB
# - Tokens/s: ~7000

# v1.0.0:
# - batch_size=1 (Step 1-50) → batch_size=6 (Step 51+)
# - 编译显存: 10GB (零 OOM 风险！)
# - 训练显存: 52GB (留 28GB 余量)
# - Tokens/s: ~10000-12000
# - 速度提升: +50%


# ========================================
# 其他硬件配置
# ========================================

# A100 40GB:
# --batch_size 4 \
# (Phase 3 会自动切换到 batch_size=4)

# H800 80GB / A100 80GB:
# --batch_size 6 \
# (推荐配置，已实测验证)

# 如果想更激进（需自行测试）:
# --batch_size 8 \


# ========================================
# 故障排查
# ========================================

# 如果编译阶段还是 OOM（极少发生）:
# 1. 检查是否有其他进程占用显存: nvidia-smi
# 2. 降低 max_seq_len: --max_seq_len 4096

# 如果 Phase 3 OOM:
# 1. 降低目标 batch_size: --batch_size 4
# 2. 增加梯度累积: --gradient_accumulation_steps 16

# 查看当前阶段:
# 日志中会显示:
# - Step 10: "✅ FlexAttention 编译完成！"
# - Step 50: "🚀 切换到 Phase 3"
