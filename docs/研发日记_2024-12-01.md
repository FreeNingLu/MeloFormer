# MeloFormer ç ”å‘æ—¥è®° - 2024-12-01

## ğŸ“‹ ä»Šæ—¥æ‘˜è¦

| ç»´åº¦ | å†…å®¹ |
|------|------|
| **What** | å®Œæˆ MeloFormer v0.5.0 ä»£ç ç²¾ç®€ + v0.8 FlexAttention æ··åˆç²¾åº¦å…¼å®¹æ€§ä¿®å¤ |
| **Why** | 1) ç²¾ç®€ä»£ç ä¾¿äºå‘å¸ƒ 2) è§£å†³ FlexAttention + BF16 + Gradient Checkpointing ä¸å…¼å®¹é—®é¢˜ |
| **When** | v0.5.0 å·²å‘å¸ƒåˆ° GitHubï¼Œv0.8 æœ¬åœ°éªŒè¯å®Œæˆ |
| **è®¡åˆ’** | åœ¨ H800 æœåŠ¡å™¨éƒ¨ç½²è®­ç»ƒç¯å¢ƒ + ä¸Šä¼ é¢„å¤„ç†æ•°æ® |

---

## ğŸ¯ æ ¸å¿ƒè¿›å±•

### 1. MeloFormer v0.5.0 ä»£ç ç²¾ç®€ä¸å‘å¸ƒ âœ…

**ç²¾ç®€å†…å®¹**ï¼š

| åˆ é™¤çš„æ–‡ä»¶/ç›®å½• | åŸå›  |
|----------------|------|
| `_archived/` | æ—§ä»£ç å’Œæ–‡æ¡£å¤‡ä»½ |
| `valid_midi_files.txt` | 60MB æ–‡ä»¶åˆ—è¡¨ï¼Œè·¯å¾„ä¾èµ–æœ¬åœ°ç¯å¢ƒ |
| `test_local.py` | å¼€å‘æµ‹è¯•è„šæœ¬ |
| `test_train_flow.py` | å¼€å‘æµ‹è¯•è„šæœ¬ |
| `PROJECT_STRUCTURE.md` | å†—ä½™æ–‡æ¡£ |
| `data/dataset.py` | æœªè¢« train.py ä½¿ç”¨çš„æ•°æ®é›†ç±» |

**train.py ä¼˜åŒ–**ï¼š
- æ–‡æ¡£å­—ç¬¦ä¸²ä» 24 è¡Œå‹ç¼©åˆ° 1 è¡Œ
- æ‰€æœ‰ import è¯­å¥ç§»è‡³æ–‡ä»¶é¡¶éƒ¨
- åˆ é™¤ 4 å¤„é‡å¤çš„ `import json`, `import random`
- åˆ é™¤ 5 å¤„åˆ†éš”æ³¨é‡Šå—

**ç²¾ç®€æ•ˆæœ**ï¼š
| æŒ‡æ ‡ | ç²¾ç®€å‰ | ç²¾ç®€å | å‹ç¼©æ¯” |
|------|--------|--------|--------|
| åŒ…å¤§å° | ~9MB | 55KB | 163x |
| æ–‡ä»¶æ•° | 20+ | 18 | - |

**GitHub å‘å¸ƒ**ï¼š
- ä»“åº“åœ°å€: https://github.com/FreeNingLu/MeloFormer
- ç‰ˆæœ¬: v0.5.0
- ç›®å½•é‡å‘½å: `hid_museformer_v0.2` â†’ `hid_museformer_v0.5`

---

### 2. FlexAttention + æ··åˆç²¾åº¦å…¼å®¹æ€§ä¿®å¤ âœ… (v0.8)

**é—®é¢˜æè¿°**ï¼š
FlexAttention åœ¨æ··åˆç²¾åº¦ (BF16/FP16) + Gradient Checkpointing ä¸‹ï¼Œåå‘ä¼ æ’­æ—¶å‡ºç° dtype ä¸åŒ¹é…é”™è¯¯ï¼š

```
RuntimeError: expected scalar type BFloat16 but found Float
```

**æ ¹æœ¬åŸå› **ï¼šFlexAttention çš„ `sdpa_dense_backward` åœ¨åå‘ä¼ æ’­æ—¶è®¡ç®— `softmax_scores` ä½¿ç”¨ FP32ï¼Œä½†æœŸæœ› `query.dtype` åŒ¹é…ã€‚

**å°è¯•çš„æ–¹æ¡ˆ**ï¼š

| æ–¹æ¡ˆ | æè¿° | ç»“æœ |
|------|------|------|
| æ–¹æ¡ˆ 1 | Checkpoint ä¸­åŒ…è£¹ autocast ä¸Šä¸‹æ–‡ | âŒ å¤±è´¥ |
| æ–¹æ¡ˆ 2 | é€‰æ‹©æ€§ checkpoint (åª checkpoint FFN) | âŒ å¤±è´¥ |
| **æ–¹æ¡ˆ 3** | **å¼ºåˆ¶ FlexAttention ä½¿ç”¨ FP32** | âœ… **æˆåŠŸ** |

**æœ€ç»ˆä¿®å¤**ï¼š
```python
# === é˜¶æ®µ 1: Summarize (SS + SR) ===
with torch.autocast(device_type='cuda', enabled=False):
    sum_q_fp32 = sum_q.float()
    sum_k_fp32 = sum_k.float()
    sum_v_fp32 = sum_v.float()

    sum_attn_out = flex_attention(sum_q_fp32, cat_k_sum, cat_v_sum,
                                   block_mask=summarize_block_mask)
    sum_attn_out = sum_attn_out.to(sum_q.dtype)  # è½¬å›åŸå§‹ dtype
```

**ä»£ä»·**ï¼šFlexAttention ä½¿ç”¨ FP32 å¯¼è‡´æ˜¾å­˜å ç”¨å¢åŠ çº¦ 50%

---

### 3. é€‰æ‹©æ€§ Gradient Checkpointing âœ…

**ç­–ç•¥**ï¼š
- **Attention éƒ¨åˆ†**: æ­£å¸¸æ‰§è¡Œ (ä¸ checkpoint)ï¼Œé¿å… FlexAttention dtype é—®é¢˜
- **FFN éƒ¨åˆ†**: ä½¿ç”¨ checkpoint èŠ‚çœæ˜¾å­˜

```python
def _checkpoint_forward(self, layer, sum_x, x, summarize_mask, updating_mask):
    # Attention éƒ¨åˆ† - æ­£å¸¸æ‰§è¡Œ
    sum_x, x = layer.attention(sum_x, x, summarize_mask, updating_mask)

    # FFN éƒ¨åˆ† - ä½¿ç”¨ checkpoint
    def ffn_forward(sum_x, x):
        sum_x = layer._apply_ffn(sum_x, is_summary=True)
        x = layer._apply_ffn(x, is_summary=False)
        return sum_x, x

    sum_x, x = torch.utils.checkpoint.checkpoint(
        ffn_forward, sum_x, x, use_reentrant=False
    )
    return sum_x, x
```

---

### 4. 32GB GPU æ˜¾å­˜æµ‹è¯• âœ…

**æµ‹è¯•ç»“æœ**ï¼š

| æ¨¡å‹ | seq_len | batch | æ˜¾å­˜ | çŠ¶æ€ |
|------|---------|-------|------|------|
| small | 4096 | 2 | ~8 GB | âœ… |
| small | 16384 | 1 | ~20 GB | âœ… |
| small | 24576 | 1 | ~30+ GB | âŒ OOM |
| base | 8192 | 4 | ~32+ GB | âŒ OOM |

**32GB GPU æ¨èé…ç½®**ï¼š

| æ¨¡å‹ | æœ€å¤§ seq_len | batch | æ¢¯åº¦ç´¯ç§¯ |
|------|-------------|-------|---------|
| small | 16384-20480 | 1 | 32 |
| base | 8192-10240 | 1 | 32 |

---

### 5. è®­ç»ƒé€Ÿåº¦åŸºå‡†æµ‹è¯• âœ…

**æµ‹è¯•é…ç½®**ï¼šsmall æ¨¡å‹, seq=4096, batch=2, 32GB GPU

| Epoch | æ—¶é—´ | Tokens/sec | è¯´æ˜ |
|-------|------|------------|------|
| 1 | 83.5s | ~2,161 | é¢„çƒ­ + ç¼–è¯‘ |
| 2 | 37.2s | ~6,465 | ç¼–è¯‘å®Œæˆ |
| 3 | 19.5s | ~8,811 | ç¨³å®šçŠ¶æ€ |

**ç¨³å®šååé‡**: ~7,500 tokens/sec

---

## ğŸ“Š æŠ€æœ¯äº®ç‚¹

### 1. Summary Token + FlexAttention æ¶æ„

**å››é˜¶æ®µæ³¨æ„åŠ›æœºåˆ¶**ï¼š
| é˜¶æ®µ | æè¿° | ä½œç”¨ |
|------|------|------|
| SS | Summary â†’ Summary | ç²—ç²’åº¦è·¨ bar å› æœæ³¨æ„åŠ› |
| SR | Summary â† Regular | ä¿¡æ¯å‹ç¼©ï¼Œæ¯ä¸ª Summary æ”¶é›†å¯¹åº” bar çš„ Regular tokens |
| RS | Regular â†’ Summary | è¿œè·ç¦»ä¸Šä¸‹æ–‡ï¼ŒRegular tokens çœ‹å†å² Summary |
| RR | Regular â†’ Regular | ç»†ç²’åº¦è¿‘è·ç¦»ï¼ŒåŒ bar å†…å…¨è¿æ¥ |

**ç¨€ç–ç­–ç•¥**ï¼š
- **Bar çº§**: åŒä¹å™¨å…¨è¿æ¥ï¼Œè·¨ä¹å™¨é€‰æ‹©æ€§ (offset â‰¤ 2 æˆ– 4)
- **Token ç±»å‹çº§**: T-T, T-P, P-P, V-V å¯è§ï¼ŒD ç›¸å…³éšè—

### 2. æ¨¡å‹è§„æ ¼

| Size | Params | Layers | Dim | Heads | FFN |
|------|--------|--------|-----|-------|-----|
| small | 17M | 6 | 256 | 4 | 1408 |
| base | 85M | 12 | 512 | 8 | 2816 |
| large | 200M | 16 | 768 | 12 | 4096 |
| xlarge | 450M | 24 | 1024 | 16 | 5632 |

---

## ğŸ”§ Bug ä¿®å¤

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| FlexAttention BF16 åå‘ä¼ æ’­å¤±è´¥ | PyTorch 2.5 FlexAttention å†…éƒ¨ä½¿ç”¨ FP32 è®¡ç®— softmax | å¼ºåˆ¶ä½¿ç”¨ FP32 + æ‰‹åŠ¨ dtype è½¬æ¢ |
| CUDA indexSelectLargeIndex è¶Šç•Œ | tensor æœªå¡«å……åˆ° seq_len | åœ¨ `create_block_masks` ä¸­å¡«å…… tensor |
| Gradient Checkpointing ä¸å…¼å®¹ | Attention å’Œ FFN ä¸€èµ· checkpoint | é€‰æ‹©æ€§ checkpointï¼Œåª checkpoint FFN |

---

## ğŸ“ˆ H800 è®­ç»ƒæ—¶é—´ä¼°ç®—

åŸºäº 32GB GPU æµ‹è¯•æ•°æ®æ¨ç®— 8Ã—H800 è®­ç»ƒ 45 ä¸‡é¦–æ­Œï¼š

| æ¨¡å‹ | ååé‡ | 1 Epoch | 100 Epochs |
|------|--------|---------|------------|
| small (8Ã—H800) | ~200K tok/s | ~5 å°æ—¶ | ~3 å‘¨ |
| base (8Ã—H800) | ~100K tok/s | ~10 å°æ—¶ | ~6 å‘¨ |
| large (8Ã—H800) | ~60K tok/s | ~17 å°æ—¶ | ~10 å‘¨ |

---

## ğŸ“ å…³é”®æ–‡ä»¶æ¸…å•

### ä»£ç æ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” |
|------|------|
| `model/attention_flex_summary.py` | Summary Token æ ¸å¿ƒå®ç° + FP32 workaround |
| `model/hid_museformer.py` | ä¸»æ¨¡å‹ + é€‰æ‹©æ€§ Gradient Checkpointing |
| `train.py` | è®­ç»ƒè„šæœ¬ + FP16 GradScaler |

### å‘å¸ƒæ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” |
|------|------|
| `~/Desktop/hid_museformer_v0.5.tar.gz` | v0.5.0 å‘å¸ƒåŒ… (55KB) |
| GitHub ä»“åº“ | https://github.com/FreeNingLu/MeloFormer |

### ç›®å½•ç»“æ„

```
MeloFormer/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ attention_flex.py           # RoPE, FlexFCAttentionMask
â”‚   â”œâ”€â”€ attention_flex_summary.py   # Summary Token æ ¸å¿ƒå®ç°
â”‚   â””â”€â”€ hid_museformer.py           # ä¸»æ¨¡å‹
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tokenizer_v2.py             # HID Tokenizer
â”‚   â”œâ”€â”€ midi_to_txt.py              # MIDI â†’ TXT
â”‚   â”œâ”€â”€ txt_to_midi.py              # TXT â†’ MIDI
â”‚   â”œâ”€â”€ chord_detector_music21.py   # å’Œå¼¦æ£€æµ‹
â”‚   â”œâ”€â”€ filter_midi.py              # MIDI è¿‡æ»¤
â”‚   â”œâ”€â”€ build_vocab_minimal.py      # è¯è¡¨æ„å»º
â”‚   â””â”€â”€ vocab_minimal.pkl           # é¢„æ„å»ºè¯è¡¨
â”œâ”€â”€ train.py                        # è®­ç»ƒè„šæœ¬ (å•å¡/DDP)
â”œâ”€â”€ preprocess_data.py              # æ•°æ®é¢„å¤„ç†
â”œâ”€â”€ generate.py                     # ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ README.md
â”œâ”€â”€ __init__.py
â””â”€â”€ .gitignore
```

---

## ğŸ’¡ ç»éªŒæ€»ç»“

### ä»Šæ—¥å­¦åˆ°çš„

1. **FlexAttention + æ··åˆç²¾åº¦çš„å‘**
   - PyTorch 2.5 çš„ FlexAttention å†…éƒ¨åå‘ä¼ æ’­ä½¿ç”¨ FP32
   - ä¸ Gradient Checkpointing ç»“åˆä¼šå¯¼è‡´ dtype ä¸åŒ¹é…
   - è§£å†³æ–¹æ¡ˆï¼šå¼ºåˆ¶ FlexAttention è¾“å…¥è¾“å‡ºä½¿ç”¨ FP32

2. **é€‰æ‹©æ€§ Checkpoint ç­–ç•¥**
   - ä¸æ˜¯æ‰€æœ‰å±‚éƒ½é€‚åˆ checkpoint
   - Attention å±‚æœ‰ç‰¹æ®Šçš„ dtype è¦æ±‚ï¼Œä¸é€‚åˆ checkpoint
   - FFN å±‚ç›¸å¯¹ç®€å•ï¼Œé€‚åˆ checkpoint

3. **ä»£ç ç²¾ç®€çš„ä»·å€¼**
   - 163x çš„å‹ç¼©æ¯” (9MB â†’ 55KB)
   - ä¿ç•™æ ¸å¿ƒåŠŸèƒ½ï¼Œç§»é™¤å†—ä½™ä»£ç 
   - ä¾¿äºåˆ†äº«å’Œéƒ¨ç½²

### å¾…éªŒè¯å‡è®¾

1. **FP32 Attention çš„æ€§èƒ½å½±å“**ï¼šé¢„è®¡æ˜¾å­˜å¢åŠ  50%ï¼Œé€Ÿåº¦å½±å“å¾…æµ‹
2. **H800 è®­ç»ƒæ•ˆç‡**ï¼šé¢„è®¡ 8 å¡å¯è¾¾ 200K tokens/sec
3. **PyTorch 2.6 å…¼å®¹æ€§**ï¼šå¯èƒ½ä¿®å¤ FlexAttention BF16 é—®é¢˜

---

## ğŸ“ˆ æ˜æ—¥è®¡åˆ’

### ä¸Šåˆ
- [ ] åœ¨ H800 æœåŠ¡å™¨ä¸Šå…‹éš†ä»“åº“
- [ ] é…ç½®è®­ç»ƒç¯å¢ƒ (PyTorch 2.5+, CUDA 12.1)

### ä¸‹åˆ
- [ ] ä¸Šä¼ é¢„å¤„ç†å¥½çš„æ•°æ®é›†
- [ ] æµ‹è¯•å•å¡è®­ç»ƒè„šæœ¬

### æ™šä¸Š
- [ ] éªŒè¯å¤šå¡ DDP è®­ç»ƒ
- [ ] å¯åŠ¨æ­£å¼è®­ç»ƒ (small æ¨¡å‹å…ˆè¡Œ)

---

## ğŸ“ å¤‡æ³¨

- FlexAttention FP32 æ˜¯ PyTorch 2.5 çš„å·²çŸ¥é™åˆ¶ï¼Œæœªæ¥ç‰ˆæœ¬å¯èƒ½ä¿®å¤
- åå°ä»åœ¨è¿è¡Œæ•°æ®é¢„å¤„ç†å’Œ MIDI æ•°æ®é›†æ‰“åŒ…ä»»åŠ¡
- **ç‰ˆæœ¬æ¼”è¿›**: v0.5.0 (ç²¾ç®€å‘å¸ƒ) â†’ v0.8 (æ··åˆç²¾åº¦ä¿®å¤)

---

**ç¼–å†™æ—¶é—´**: 2024-12-01 23:59
**ä¸‹æ¬¡æ›´æ–°**: 2024-12-02 (æœåŠ¡å™¨éƒ¨ç½²å)
