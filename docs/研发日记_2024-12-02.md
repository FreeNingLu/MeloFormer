# MeloFormer 研发日记

## 2024-12-02

### 今日工作概要

完成文本到音乐多模态融合方案调研，提出 **Summary Token 劫持方案**。

---

## 一、多模态融合方案对比

| 方案 | 优点 | 缺点 | 结论 |
|------|------|------|------|
| MLP 映射 | 训练快 | 映射粗糙 | ❌ |
| CLIP 对比学习 | 对齐好 | 不能生成 | ❌ |
| Adapter/Prefix | 轻量 | 表达受限 | ❌ |
| VAE 桥接 | 有生成能力 | 后验坍塌 | ❌ |
| **Diffusion Bridge** | 质量高、多样性好 | 训练慢 | ✅ 采用 |

---

## 二、Diffusion Bridge 原理

### 核心思想
模态A → 渐进式桥接 → 模态B（而非噪声 → 数据）

### 数学表达
```python
# 前向：插值 + 噪声
q(z_t | z_text, z_music) = N(z_t; α_t*z_music + (1-α_t)*z_text, β_t*I)

# 反向：训练网络预测噪声
ε_θ(z_t, z_text, t) → 预测噪声
```

---

## 三、Summary Token 劫持方案 ⭐

### 关键发现
MuseFormer 原生就有 **Fine-grained + Coarse-grained** 双层注意力：
- Fine-grained Token：具体音符
- **Coarse-grained Token（Summary Token）**：整个 Bar 的语义

**这意味着**：Summary Token 就是 MuseFormer 的"指挥棒"！

### 方案对比

| 维度 | Soft Prompt | Summary Token 劫持 |
|------|-------------|-------------------|
| 控制位置 | 输入层（间接） | 中间层核心节点（直接） |
| 训练目标 | 完整序列 | 每 bar 1 个向量 |
| 计算复杂度 | O(N×T) | O(N×B), B<<T |
| 收敛速度 | 慢 | **快 10 倍** |

---

## 四、三阶段实现

### 阶段 A：提取 Summary Token（1 周）
```python
# 冻结 MuseFormer，提取中间层 Summary Token 作为 Ground Truth
summary_tokens = museformer.get_hidden_states(midi)['summary_tokens']
```

### 阶段 B：训练 Diffusion Bridge（2-3 周）
```python
# 唯一需要训练的模块
class SummaryTokenDiffusionBridge:
    text_encoder: BertModel (冻结)
    bridge: DiffusionBridge (训练)  # 文本 → Summary Token
```

### 阶段 C：推理注入（1 周）
```python
# Hook 劫持：用 Diffusion 生成的 Summary Token 替换 MuseFormer 自己计算的
def summary_hook(module, input, output):
    return injected_summary[:, bar_idx, :]  # 直接替换

hook_handle = museformer.coarse_attention_layer.register_forward_hook(summary_hook)
```

---

## 五、核心优势

1. **维度更低**：512 维 vs 数千个 token
2. **空间更平滑**：MuseFormer 已训练好的流形
3. **映射更直接**：语义 → 语义（而非语义 → 符号）
4. **无需改动原模型**：只训练轻量桥接模块（~100M 参数）

---

## 六、数据需求

| 数据规模 | 用途 |
|---------|------|
| 1,000 对 | 最小验证 |
| 5,000-10,000 对 | 正常训练 |
| 50,000+ 对 | SOTA 效果 |

**数据来源**：
- 网易云音乐评论 + MIDI
- MusicCaps 数据集
- GPT-4 自动标注

---

## 七、实现路线图

### Week 1：特征提取
- [ ] 定位 MuseFormer Summary Token 计算位置
- [ ] 提取 1000 首 MIDI 的 Summary Token

### Week 2-3：训练桥接
- [ ] 实现 Diffusion Bridge
- [ ] 收集 5,000 对文本-MIDI
- [ ] 训练（4×V100，1 周）

### Week 4：集成测试
- [ ] Hook 注入机制
- [ ] 端到端测试
- [ ] 人类评估

---

## 八、代码定位关键字

```python
# MuseFormer 源码中查找
keywords = [
    'summary_token',
    'coarse_token',
    'coarse_attention',
    'bar_level_attention'
]

files = [
    'model/museformer.py',
    'model/attention.py'
]
```

---

## 九、风险应对

| 风险 | 应对 |
|------|------|
| Summary Token 格式不明 | PCA 可视化验证 |
| Hook 位置错误 | 注入全 0 测试 |
| 文本-音乐对齐难 | 先用简单属性标签 |

---

## 十、预期效果

**定量**：
- 训练：1 周（4×V100）
- 推理：< 1 秒/首

**定性**：
- "流星雨" → 快速、高音、跳跃、稀疏
- "暴风雨" → 低音、密集、持续、强力度

---

## 备注

- **核心创新**："夺舍"中间层而非"引导"输入层
- **下一步**：定位 MuseFormer Summary Token 代码位置
- **参考论文**：
  - I2SB: Diffusion Bridge (NeurIPS 2023)
  - MusicLDM (ICML 2023)
  - CLIP (ICML 2021)
