#!/usr/bin/env python3
"""HID-MuseFormer è®­ç»ƒè„šæœ¬ - æ”¯æŒå•å¡/DDP å¤šå¡è®­ç»ƒ"""

import os
import sys
import math
import time
import json
import random
import argparse
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime

import torch

# å¢åŠ  dynamo cache size é¿å… FlexAttention é‡ç¼–è¯‘é—®é¢˜
import torch._dynamo
torch._dynamo.config.cache_size_limit = 2048  # ä¿®å¤ï¼šStep 150 å´©æºƒï¼Œä» 512 å¢åŠ åˆ° 2048
torch._dynamo.config.accumulated_cache_size_limit = 4096  # ä¿®å¤ï¼šå¯¹åº”å¢åŠ ç´¯ç§¯ç¼“å­˜é™åˆ¶
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
import torch.distributed as dist
from tqdm import tqdm

try:
    from flash_attn import flash_attn_func
    HAS_FLASH_ATTN = True
except ImportError:
    HAS_FLASH_ATTN = False
    print("[Warning] Flash Attention not available, using PyTorch SDPA")

from model import HIDMuseFormer, create_model
from data import HIDTokenizerV2


class PreprocessedDataset(Dataset):
    """
    åŠ è½½é¢„å¤„ç†æ•°æ® - æ”¯æŒä¸¤ç§æ ¼å¼:
    1. åˆ†ç‰‡æ ¼å¼ (æ¨è): shard_0000.pt, shard_0001.pt, ... æ¯ä¸ªåˆ†ç‰‡åŒ…å«å¤šä¸ªæ ·æœ¬
    2. å•æ–‡ä»¶æ ¼å¼ (æ—§ç‰ˆ): æ¯ä¸ª .pt æ–‡ä»¶ä¸€ä¸ªæ ·æœ¬

    åˆ†ç‰‡æ ¼å¼ä½¿ç”¨æ‡’åŠ è½½ï¼Œé¿å…å†…å­˜çˆ†ç‚¸
    """

    def __init__(
        self,
        data_path: str,
        max_seq_len: int = 24576,
        max_bars: int = 2048,
        shuffle_files: bool = True,
        max_samples: int = None,
    ):
        self.max_seq_len = max_seq_len
        self.max_bars = max_bars
        self.samples = []
        self.lazy_mode = False  # æ˜¯å¦ä½¿ç”¨æ‡’åŠ è½½
        self._skipped_count = 0  # è·³è¿‡çš„æ ·æœ¬è®¡æ•°

        data_path = Path(data_path)

        # æ£€æµ‹æ•°æ®æ ¼å¼
        shard_files = sorted(data_path.glob('shard_*.pt'))

        if shard_files:
            # åˆ†ç‰‡æ ¼å¼ - ä½¿ç”¨æ‡’åŠ è½½ (åªè®°å½•ç´¢å¼•ï¼Œä¸åŠ è½½æ•°æ®)
            print(f"æ£€æµ‹åˆ°åˆ†ç‰‡æ ¼å¼: {len(shard_files)} ä¸ªåˆ†ç‰‡")

            # è¯»å– meta.json è·å–æ ·æœ¬æ•°é‡
            meta_path = data_path / 'meta.json'
            if meta_path.exists():
                with open(meta_path, 'r') as f:
                    meta = json.load(f)
                total_samples = meta.get('total_samples', 0)
                shard_size = meta.get('shard_size', 10000)
                print(f"ä» meta.json è¯»å–: {total_samples:,} ä¸ªæ ·æœ¬")
            else:
                # æ²¡æœ‰ meta.jsonï¼Œæ‰«æç¬¬ä¸€ä¸ªåˆ†ç‰‡ä¼°ç®—
                first_shard = torch.load(shard_files[0], weights_only=False)
                shard_size = len(first_shard)
                total_samples = shard_size * len(shard_files)
                del first_shard
                print(f"ä¼°ç®—æ ·æœ¬æ•°: {total_samples:,}")

            # è®¾ç½®æ‡’åŠ è½½æ¨¡å¼
            self.lazy_mode = True
            self.shard_files = shard_files
            self.shard_size = shard_size
            self.total_samples = min(total_samples, max_samples) if max_samples else total_samples

            # åˆ†ç‰‡ç¼“å­˜ (LRU ç¼“å­˜æœ€è¿‘ä½¿ç”¨çš„åˆ†ç‰‡)
            self._shard_cache = {}
            self._cache_order = []
            # 120GB å†…å­˜ä¼˜åŒ–ï¼šç¼“å­˜ 30 ä¸ªåˆ†ç‰‡ï¼ˆçº¦å ç”¨ 30-35GBï¼‰
            # æ¸è¿›å¼åˆ‡æ¢ç­–ç•¥ï¼šStep 50 æ‰åˆ‡æ¢åˆ° num_workers=8
            # ç»™ç¼–è¯‘å’Œåˆå§‹è®­ç»ƒé¢„ç•™è¶³å¤Ÿå†…å­˜ç¼“å†²
            self._max_cache_size = 30  # å¹³è¡¡é€Ÿåº¦å’Œå†…å­˜å®‰å…¨

            # æ„å»ºç´¢å¼•æ˜ å°„: global_idx -> (shard_idx, local_idx)
            self.index_map = []
            sample_count = 0
            for shard_idx, shard_file in enumerate(shard_files):
                # æœ€åä¸€ä¸ªåˆ†ç‰‡å¯èƒ½ä¸æ»¡
                if shard_idx == len(shard_files) - 1:
                    remaining = self.total_samples - sample_count
                    shard_samples = remaining
                else:
                    shard_samples = shard_size

                for local_idx in range(shard_samples):
                    if max_samples and sample_count >= max_samples:
                        break
                    self.index_map.append((shard_idx, local_idx))
                    sample_count += 1

                if max_samples and sample_count >= max_samples:
                    break

            # Shuffle ç´¢å¼•
            if shuffle_files:
                random.shuffle(self.index_map)

            print(f"æ‡’åŠ è½½æ¨¡å¼: {len(self.index_map):,} ä¸ªæ ·æœ¬ (ç¼“å­˜ {self._max_cache_size} ä¸ªåˆ†ç‰‡)")

        else:
            # å•æ–‡ä»¶æ ¼å¼ (æ—§ç‰ˆå…¼å®¹) - ä»ç„¶åŠ è½½åˆ°å†…å­˜
            if data_path.is_file():
                with open(data_path, 'r') as f:
                    files = [line.strip() for line in f if line.strip()]
            else:
                files = [str(f) for f in data_path.glob('*.pt')]

            if shuffle_files:
                random.shuffle(files)

            if max_samples:
                files = files[:max_samples]

            print(f"æ£€æµ‹åˆ°å•æ–‡ä»¶æ ¼å¼: {len(files)} ä¸ªæ–‡ä»¶")
            for f in tqdm(files, desc="åŠ è½½æ–‡ä»¶"):
                try:
                    data = torch.load(f, weights_only=True)
                    if data['length'] > max_seq_len:
                        for key in ['token_ids', 'chord_ids', 'position_ids', 'instrument_ids', 'token_type_ids', 'note_ids']:
                            if key in data:
                                data[key] = data[key][:max_seq_len]
                        data['length'] = max_seq_len
                    self.samples.append(data)
                except:
                    pass

            print(f"å·²åŠ è½½ {len(self.samples):,} ä¸ªæ ·æœ¬åˆ°å†…å­˜")

            if shuffle_files:
                random.shuffle(self.samples)

    def _load_shard(self, shard_idx: int):
        """åŠ è½½åˆ†ç‰‡ (å¸¦ LRU ç¼“å­˜)"""
        if shard_idx in self._shard_cache:
            # ç§»åˆ°æœ€è¿‘ä½¿ç”¨
            self._cache_order.remove(shard_idx)
            self._cache_order.append(shard_idx)
            return self._shard_cache[shard_idx]

        # åŠ è½½æ–°åˆ†ç‰‡
        shard_data = torch.load(self.shard_files[shard_idx], weights_only=False)

        # ç¼“å­˜ç®¡ç†
        if len(self._cache_order) >= self._max_cache_size:
            # åˆ é™¤æœ€æ—§çš„
            oldest = self._cache_order.pop(0)
            del self._shard_cache[oldest]

        self._shard_cache[shard_idx] = shard_data
        self._cache_order.append(shard_idx)

        return shard_data

    def __len__(self) -> int:
        if self.lazy_mode:
            return len(self.index_map)
        return len(self.samples)

    def __getitem__(self, idx: int) -> Optional[Dict[str, torch.Tensor]]:
        if self.lazy_mode:
            shard_idx, local_idx = self.index_map[idx]
            shard_data = self._load_shard(shard_idx)
            sample = shard_data[local_idx]
        else:
            sample = self.samples[idx]

        # æ£€æŸ¥ bar æ•°é‡æ˜¯å¦è¶…è¿‡ max_bars
        if 'chord_ids' in sample:
            num_bars = sample['chord_ids'].max().item() + 1
            if num_bars > self.max_bars:
                self._skipped_count += 1
                return None  # è·³è¿‡è¶…é•¿æ ·æœ¬

        # æˆªæ–­åºåˆ—é•¿åº¦
        if sample['length'] > self.max_seq_len:
            sample = {k: v[:self.max_seq_len] if isinstance(v, torch.Tensor) else v for k, v in sample.items()}
            sample['length'] = self.max_seq_len

        return sample


def efficient_collate_fn(batch: List[Optional[Dict]]) -> Optional[Dict[str, torch.Tensor]]:
    """
    é«˜æ•ˆçš„æ‰¹æ¬¡æ•´ç†å‡½æ•°
    - åºåˆ—é•¿åº¦åˆ†æ¡¶: å‡å°‘ FlexAttention é‡ç¼–è¯‘æ¬¡æ•°
    - åŠ¨æ€ padding åˆ° batch å†…æœ€å¤§é•¿åº¦ (å‡å°‘æ— æ•ˆè®¡ç®—)
    - è¿‡æ»¤æ‰ None æ ·æœ¬ (è¶…è¿‡ max_bars çš„æ ·æœ¬)
    """
    # è¿‡æ»¤æ‰ None æ ·æœ¬
    batch = [x for x in batch if x is not None]
    if len(batch) == 0:
        return None  # æ•´ä¸ª batch éƒ½è¢«è·³è¿‡

    # æŒ‰é•¿åº¦æ’åº (å‡å°‘ padding)
    batch = sorted(batch, key=lambda x: x['length'], reverse=True)

    max_len = batch[0]['length']

    # åºåˆ—é•¿åº¦åˆ†æ¡¶ (å…³é”®ä¼˜åŒ–ï¼)
    # å°† max_len å‘ä¸Šå–æ•´åˆ°æœ€è¿‘çš„æ¡¶è¾¹ç•Œ
    # æ¡¶å¤§å°: 512 tokens
    # è¿™æ · FlexAttention åªéœ€è¦ç¼–è¯‘ 16 ä¸ª kernel (8192/512=16)
    BUCKET_SIZE = 512
    max_len = ((max_len + BUCKET_SIZE - 1) // BUCKET_SIZE) * BUCKET_SIZE
    max_len = min(max_len, 8192)  # ä¸è¶…è¿‡ max_seq_len
    batch_size = len(batch)

    # é¢„åˆ†é…å¼ é‡
    token_ids = torch.zeros(batch_size, max_len, dtype=torch.long)
    labels = torch.full((batch_size, max_len), -100, dtype=torch.long)
    chord_ids = torch.full((batch_size, max_len), -1, dtype=torch.long)
    position_ids = torch.full((batch_size, max_len), -1, dtype=torch.long)
    instrument_ids = torch.full((batch_size, max_len), 129, dtype=torch.long)
    token_type_ids = torch.full((batch_size, max_len), -1, dtype=torch.long)  # Token ç±»å‹
    note_ids = torch.full((batch_size, max_len), -1, dtype=torch.long)  # éŸ³ç¬¦ ID
    lengths = torch.zeros(batch_size, dtype=torch.long)

    for i, item in enumerate(batch):
        length = item['length']
        token_ids[i, :length] = item['token_ids']
        labels[i, :length] = item['token_ids']
        chord_ids[i, :length] = item['chord_ids']
        position_ids[i, :length] = item['position_ids']
        instrument_ids[i, :length] = item['instrument_ids']
        # Token Type Sparsity éœ€è¦çš„å­—æ®µ
        if 'token_type_ids' in item:
            token_type_ids[i, :length] = item['token_type_ids']
        if 'note_ids' in item:
            note_ids[i, :length] = item['note_ids']
        lengths[i] = length

    return {
        'token_ids': token_ids,
        'labels': labels,
        'chord_ids': chord_ids,
        'position_ids': position_ids,
        'instrument_ids': instrument_ids,
        'token_type_ids': token_type_ids,
        'note_ids': note_ids,
        'lengths': lengths,
    }


def setup_distributed():
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ"""
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        rank = int(os.environ['RANK'])
        world_size = int(os.environ['WORLD_SIZE'])
        local_rank = int(os.environ.get('LOCAL_RANK', 0))
    else:
        rank = 0
        world_size = 1
        local_rank = 0

    if world_size > 1:
        dist.init_process_group(backend='nccl')
        torch.cuda.set_device(local_rank)

    return rank, world_size, local_rank


def cleanup_distributed():
    """æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒ"""
    if dist.is_initialized():
        dist.destroy_process_group()


def get_cosine_schedule_with_warmup(
    optimizer,
    num_warmup_steps: int,
    num_training_steps: int,
    min_lr_ratio: float = 0.1,
):
    """
    ä½™å¼¦é€€ç« + çº¿æ€§é¢„çƒ­
    """
    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        return max(min_lr_ratio, 0.5 * (1.0 + math.cos(math.pi * progress)))

    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)


class H800Trainer:
    """
    H800 ä¼˜åŒ–è®­ç»ƒå™¨
    """

    def __init__(
        self,
        model: nn.Module,
        train_dataset: Dataset,
        val_dataset: Optional[Dataset] = None,
        args: argparse.Namespace = None,
    ):
        self.args = args
        self.rank, self.world_size, self.local_rank = setup_distributed()
        self.is_main = self.rank == 0

        # è®¾å¤‡
        self.device = torch.device(f'cuda:{self.local_rank}')

        # æ¨¡å‹
        self.model = model.to(self.device)

        # Gradient Checkpointing
        if args.gradient_checkpointing:
            self.model.gradient_checkpointing_enable()
            if self.is_main:
                print("[âœ“] Gradient Checkpointing enabled")

        # torch.compile (PyTorch 2.0+)
        if args.compile and hasattr(torch, 'compile'):
            self.model = torch.compile(self.model, mode='reduce-overhead')
            if self.is_main:
                print("[âœ“] torch.compile enabled")

        # DDP
        if self.world_size > 1:
            self.model = DDP(
                self.model,
                device_ids=[self.local_rank],
                find_unused_parameters=False,
            )

        # æ•°æ®åŠ è½½å™¨ (ä¸‰é˜¶æ®µåŠ¨æ€ä¼˜åŒ–)
        # Phase 1 (Step 1-10): batch_size=1, num_workers=0
        #   - é¿å…å¤šè¿›ç¨‹ + ç¼–è¯‘å†²çª
        # Phase 2 (Step 11-100): batch_size=1, num_workers=8
        #   - åŠ é€Ÿæ•°æ®åŠ è½½ï¼ŒGPU åˆ©ç”¨ç‡æå‡
        #   - ç»§ç»­ç”¨å° batch é¿å…ç¼–è¯‘æ—¶ OOM
        # Phase 3 (Step 101+): batch_size=ç›®æ ‡å€¼, num_workers=8
        #   - å…¨é€Ÿè®­ç»ƒ
        self._phase = 1  # å½“å‰é˜¶æ®µ
        self._compilation_batch_size = 1  # ç¼–è¯‘é˜¶æ®µæœ€å° batch
        self._target_batch_size = args.batch_size  # è®­ç»ƒé˜¶æ®µç›®æ ‡ batch
        self._target_num_workers = args.num_workers if args.num_workers > 0 else 8

        self.train_dataset = train_dataset
        self.val_dataset = val_dataset

        train_sampler = DistributedSampler(train_dataset, shuffle=True) if self.world_size > 1 else None
        self.train_sampler = train_sampler
        self.train_loader = DataLoader(
            train_dataset,
            batch_size=self._compilation_batch_size,  # Phase 1: ä» batch_size=1 å¼€å§‹
            shuffle=(train_sampler is None),
            sampler=train_sampler,
            num_workers=0,  # Phase 1: ç¼–è¯‘æ—¶ç”¨ 0 é¿å… OOM
            collate_fn=efficient_collate_fn,
            pin_memory=True,
            prefetch_factor=None,
            persistent_workers=False,
        )

        if val_dataset is not None:
            val_sampler = DistributedSampler(val_dataset, shuffle=False) if self.world_size > 1 else None
            self.val_sampler = val_sampler
            self.val_loader = DataLoader(
                val_dataset,
                batch_size=self._compilation_batch_size,  # Phase 1: éªŒè¯é›†ä¹Ÿç”¨æœ€å° batch
                shuffle=False,
                sampler=val_sampler,
                num_workers=0,
                collate_fn=efficient_collate_fn,
                pin_memory=True,
            )
        else:
            self.val_loader = None

        # ä¼˜åŒ–å™¨ (ä½¿ç”¨ fused Adam)
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=args.learning_rate,
            weight_decay=args.weight_decay,
            betas=(0.9, 0.95),
            fused=True,  # H800 ä¼˜åŒ–
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        total_steps = len(self.train_loader) * args.epochs // args.gradient_accumulation_steps
        self.scheduler = get_cosine_schedule_with_warmup(
            self.optimizer,
            num_warmup_steps=args.warmup_steps,
            num_training_steps=total_steps,
        )

        # æ··åˆç²¾åº¦é…ç½®
        # BF16: H800/A100 åŸç”Ÿæ”¯æŒï¼Œæ›´ç¨³å®šï¼Œä¸éœ€è¦ GradScaler
        # FP16: éœ€è¦ GradScaler é˜²æ­¢æ¢¯åº¦ä¸‹æº¢
        if args.fp16:
            self.scaler = torch.amp.GradScaler('cuda')
            self.autocast_dtype = torch.float16
            if self.is_main:
                print("[âœ“] FP16 æ··åˆç²¾åº¦ (GradScaler enabled)")
        elif args.bf16:
            self.scaler = None  # BF16 ä¸éœ€è¦ GradScaler
            self.autocast_dtype = torch.bfloat16
            if self.is_main:
                print("[âœ“] BF16 æ··åˆç²¾åº¦")
        else:
            self.scaler = None
            self.autocast_dtype = torch.float32
            if self.is_main:
                print("[âœ“] FP32 ç²¾åº¦")

        # FlexAttention + Gradient Checkpointing + æ··åˆç²¾åº¦å…¼å®¹æ€§å¤„ç†
        # å°† autocast_dtype ä¼ é€’ç»™æ¨¡å‹ï¼Œç”¨äºé€‰æ‹©æ€§ checkpoint
        if args.gradient_checkpointing:
            base_model = self.model.module if hasattr(self.model, 'module') else self.model
            base_model._autocast_dtype = self.autocast_dtype

        # çŠ¶æ€
        self.global_step = 0
        self.epoch = 0
        self.best_val_loss = float('inf')

        # æ—¥å¿—
        self.log_dir = Path(args.output_dir) / 'logs'
        self.checkpoint_dir = Path(args.output_dir) / 'checkpoints'

        if self.is_main:
            self.log_dir.mkdir(parents=True, exist_ok=True)
            self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

            # WandB
            if args.use_wandb:
                import wandb
                wandb.init(
                    project=args.wandb_project,
                    name=args.run_name or f"hid-museformer-h800-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
                    config=vars(args),
                )

    def _switch_to_phase_3(self):
        """Phase 3: åˆ‡æ¢åˆ°æœ€å¤§ batch_size + å¤š worker æ¨¡å¼"""
        if self._phase >= 3:
            return

        self._phase = 3
        if self.is_main:
            print(f"\n{'='*60}")
            print(f"ğŸš€ åˆ‡æ¢åˆ° Phase 3 (é«˜é€Ÿè®­ç»ƒæ¨¡å¼)")
            print(f"ğŸ“Š batch_size: {self._compilation_batch_size} â†’ {self._target_batch_size}")
            print(f"ğŸ‘· num_workers: 0 â†’ {self._target_num_workers}")
            print(f"âš¡ é¢„æœŸåŠ é€Ÿ: {self._target_batch_size / self._compilation_batch_size:.1f}x")
            print(f"{'='*60}\n")

        # é‡å»º train_loader
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=self._target_batch_size,  # åˆ‡æ¢åˆ°ç›®æ ‡ batch_size
            shuffle=(self.train_sampler is None),
            sampler=self.train_sampler,
            num_workers=self._target_num_workers,  # åˆ‡æ¢åˆ°å¤š worker
            collate_fn=efficient_collate_fn,
            pin_memory=True,
            prefetch_factor=4 if self._target_num_workers > 0 else None,
            persistent_workers=self._target_num_workers > 0,
        )

        # é‡å»º val_loader
        if self.val_dataset is not None:
            self.val_loader = DataLoader(
                self.val_dataset,
                batch_size=self._target_batch_size,  # éªŒè¯é›†ä¹Ÿåˆ‡æ¢
                shuffle=False,
                sampler=self.val_sampler,
                num_workers=self._target_num_workers,
                collate_fn=efficient_collate_fn,
                pin_memory=True,
            )

    def train_epoch(self) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()
        total_loss = 0.0
        total_tokens = 0
        num_batches = 0

        start_time = time.time()

        if self.world_size > 1:
            self.train_loader.sampler.set_epoch(self.epoch)

        self.optimizer.zero_grad(set_to_none=True)  # æ›´é«˜æ•ˆ

        for batch_idx, batch in enumerate(self.train_loader):
            # è·³è¿‡ç©º batch (æ‰€æœ‰æ ·æœ¬éƒ½è¶…è¿‡ max_bars)
            if batch is None:
                continue

            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡ (non_blocking)
            token_ids = batch['token_ids'].to(self.device, non_blocking=True)
            labels = batch['labels'].to(self.device, non_blocking=True)
            chord_ids = batch['chord_ids'].to(self.device, non_blocking=True)
            instrument_ids = batch['instrument_ids'].to(self.device, non_blocking=True)
            token_type_ids = batch['token_type_ids'].to(self.device, non_blocking=True)
            note_ids = batch['note_ids'].to(self.device, non_blocking=True)

            # å‰å‘ä¼ æ’­ (BF16/FP16)
            with torch.autocast(device_type='cuda', dtype=self.autocast_dtype):
                logits = self.model(
                    token_ids,
                    chord_ids=chord_ids,
                    instrument_ids=instrument_ids,
                    token_type_ids=token_type_ids,
                    note_ids=note_ids,
                )

                # è®¡ç®—æŸå¤±
                shift_logits = logits[:, :-1, :].contiguous()
                shift_labels = labels[:, 1:].contiguous()

                loss = F.cross_entropy(
                    shift_logits.view(-1, shift_logits.size(-1)),
                    shift_labels.view(-1),
                    ignore_index=-100,
                )
                loss = loss / self.args.gradient_accumulation_steps

            # åå‘ä¼ æ’­ (æ”¯æŒ GradScaler)
            if self.scaler is not None:
                self.scaler.scale(loss).backward()
            else:
                loss.backward()

            batch_tokens = (labels != -100).sum().item()
            total_loss += loss.item() * self.args.gradient_accumulation_steps
            total_tokens += batch_tokens
            num_batches += 1

            # æ¢¯åº¦ç´¯ç§¯
            if (batch_idx + 1) % self.args.gradient_accumulation_steps == 0:
                if self.scaler is not None:
                    # FP16: ä½¿ç”¨ GradScaler
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    # BF16/FP32: ç›´æ¥ä¼˜åŒ–
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)
                    self.optimizer.step()

                self.scheduler.step()
                self.optimizer.zero_grad(set_to_none=True)
                self.global_step += 1

                # ä¸‰é˜¶æ®µåŠ¨æ€åˆ‡æ¢ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
                # Phase 1 (Step 1-10): batch_size=1, num_workers=0 (ç¼–è¯‘åˆæœŸï¼Œé¿å…å¤šè¿›ç¨‹å†²çª)
                # Phase 2 (Step 11-100): batch_size=1, num_workers=8 (ç¼–è¯‘ä¸­æœŸï¼ŒåŠ é€Ÿæ•°æ®åŠ è½½)
                # Phase 3 (Step 101+): batch_size=6, num_workers=8 (è®­ç»ƒé˜¶æ®µï¼Œå…¨é€Ÿ)
                if self.global_step == 10:
                    # åˆ‡æ¢åˆ° num_workers=8ï¼Œä½†ä¿æŒ batch_size=1
                    if self.is_main:
                        print(f"\n{'='*60}")
                        print(f"ğŸ”„ Phase 2: åˆ‡æ¢æ•°æ®åŠ è½½")
                        print(f"ğŸ‘· num_workers: 0 â†’ {self._target_num_workers}")
                        print(f"ğŸ“Š batch_size: {self._compilation_batch_size} (ä¿æŒ)")
                        print(f"âš¡ é¢„æœŸ: GPU åˆ©ç”¨ç‡æå‡ï¼Œç¼–è¯‘ç»§ç»­...")
                        print(f"{'='*60}\n")

                    self._phase = 2

                    # é‡å»º DataLoaderï¼ˆåªæ”¹ num_workersï¼‰
                    self.train_loader = DataLoader(
                        self.train_dataset,
                        batch_size=self._compilation_batch_size,  # ä¿æŒ batch_size=1
                        shuffle=(self.train_sampler is None),
                        sampler=self.train_sampler,
                        num_workers=self._target_num_workers,  # åˆ‡æ¢åˆ° 8 workers
                        collate_fn=efficient_collate_fn,
                        pin_memory=True,
                        prefetch_factor=4 if self._target_num_workers > 0 else None,
                        persistent_workers=self._target_num_workers > 0,
                    )

                elif self.global_step == 100:
                    # åˆ‡æ¢åˆ°æœ€å¤§ batch_size
                    self._switch_to_phase_3()

                # æ—¥å¿—
                if self.is_main and self.global_step % self.args.log_interval == 0:
                    elapsed = time.time() - start_time
                    avg_loss = total_loss / num_batches
                    tokens_per_sec = total_tokens / elapsed
                    lr = self.scheduler.get_last_lr()[0]

                    print(f"Step {self.global_step} | "
                          f"Loss: {avg_loss:.4f} | "
                          f"LR: {lr:.2e} | "
                          f"Tokens/s: {tokens_per_sec:.0f}")

                    if self.args.use_wandb:
                        import wandb
                        wandb.log({
                            'train/loss': avg_loss,
                            'train/learning_rate': lr,
                            'train/tokens_per_sec': tokens_per_sec,
                            'train/step': self.global_step,
                        })

                # ä¿å­˜æ£€æŸ¥ç‚¹
                if self.is_main and self.global_step % self.args.save_interval == 0:
                    self.save_checkpoint(f'step_{self.global_step}')

        return {'loss': total_loss / max(num_batches, 1)}

    @torch.no_grad()
    def validate(self) -> Dict[str, float]:
        """éªŒè¯"""
        if self.val_loader is None:
            return {}

        self.model.eval()
        total_loss = 0.0
        num_batches = 0

        for batch in self.val_loader:
            if batch is None:
                continue
            token_ids = batch['token_ids'].to(self.device, non_blocking=True)
            labels = batch['labels'].to(self.device, non_blocking=True)
            chord_ids = batch['chord_ids'].to(self.device, non_blocking=True)
            instrument_ids = batch['instrument_ids'].to(self.device, non_blocking=True)
            token_type_ids = batch['token_type_ids'].to(self.device, non_blocking=True)
            note_ids = batch['note_ids'].to(self.device, non_blocking=True)

            with torch.autocast(device_type='cuda', dtype=self.autocast_dtype):
                logits = self.model(
                    token_ids,
                    chord_ids=chord_ids,
                    instrument_ids=instrument_ids,
                    token_type_ids=token_type_ids,
                    note_ids=note_ids,
                )

                shift_logits = logits[:, :-1, :].contiguous()
                shift_labels = labels[:, 1:].contiguous()

                loss = F.cross_entropy(
                    shift_logits.view(-1, shift_logits.size(-1)),
                    shift_labels.view(-1),
                    ignore_index=-100,
                )

            total_loss += loss.item()
            num_batches += 1

        avg_loss = total_loss / max(num_batches, 1)

        # èšåˆåˆ†å¸ƒå¼ç»“æœ
        if self.world_size > 1:
            loss_tensor = torch.tensor([avg_loss], device=self.device)
            dist.all_reduce(loss_tensor, op=dist.ReduceOp.SUM)
            avg_loss = loss_tensor.item() / self.world_size

        return {'val_loss': avg_loss}

    def train(self):
        """å®Œæ•´è®­ç»ƒå¾ªç¯"""
        if self.is_main:
            print("\n" + "=" * 60)
            print("HID-MuseFormer H800 è®­ç»ƒ")
            print("=" * 60)
            print(f"è®¾å¤‡: {self.device}")
            print(f"ä¸–ç•Œå¤§å°: {self.world_size}")
            print(f"æ‰¹å¤§å° (per GPU): {self.args.batch_size}")
            print(f"æ¢¯åº¦ç´¯ç§¯: {self.args.gradient_accumulation_steps}")
            print(f"æœ‰æ•ˆæ‰¹å¤§å°: {self.args.batch_size * self.world_size * self.args.gradient_accumulation_steps}")
            print(f"Epochs: {self.args.epochs}")
            print(f"å­¦ä¹ ç‡: {self.args.learning_rate}")
            print(f"æ··åˆç²¾åº¦: {'BF16' if self.args.bf16 else ('FP16' if self.args.fp16 else 'FP32')}")
            print(f"Flash Attention: {'Yes' if HAS_FLASH_ATTN else 'No (using SDPA)'}")
            print("=" * 60 + "\n")

        for epoch in range(self.args.epochs):
            self.epoch = epoch

            if self.is_main:
                print(f"\n{'='*50}")
                print(f"Epoch {epoch + 1}/{self.args.epochs}")
                print(f"{'='*50}")

            epoch_start = time.time()

            # è®­ç»ƒ
            train_metrics = self.train_epoch()

            # éªŒè¯
            val_metrics = self.validate()

            epoch_time = time.time() - epoch_start

            if self.is_main:
                print(f"Epoch {epoch + 1} | "
                      f"Train Loss: {train_metrics['loss']:.4f} | "
                      f"Time: {epoch_time:.1f}s", end='')

                if val_metrics:
                    print(f" | Val Loss: {val_metrics['val_loss']:.4f}", end='')

                    if val_metrics['val_loss'] < self.best_val_loss:
                        self.best_val_loss = val_metrics['val_loss']
                        self.save_checkpoint('best')
                        print(" (best)", end='')

                print()

                if self.args.use_wandb:
                    import wandb
                    wandb.log({
                        'epoch': epoch + 1,
                        'epoch_time': epoch_time,
                        **{f'train/{k}': v for k, v in train_metrics.items()},
                        **{f'val/{k}': v for k, v in val_metrics.items()},
                    })

            # ä¿å­˜ epoch æ£€æŸ¥ç‚¹
            if self.is_main:
                self.save_checkpoint(f'epoch_{epoch + 1}')

        if self.is_main:
            print("\nè®­ç»ƒå®Œæˆï¼")
            self.save_checkpoint('final')

    def save_checkpoint(self, name: str):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model

        checkpoint = {
            'model_state_dict': model_to_save.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'epoch': self.epoch,
            'global_step': self.global_step,
            'best_val_loss': self.best_val_loss,
            'args': vars(self.args),
        }

        path = self.checkpoint_dir / f'{name}.pt'
        torch.save(checkpoint, path)
        print(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {path}")

    def load_checkpoint(self, path: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(path, map_location=self.device)

        model_to_load = self.model.module if hasattr(self.model, 'module') else self.model
        model_to_load.load_state_dict(checkpoint['model_state_dict'])

        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        self.epoch = checkpoint['epoch']
        self.global_step = checkpoint['global_step']
        self.best_val_loss = checkpoint['best_val_loss']

        print(f"æ£€æŸ¥ç‚¹å·²åŠ è½½: {path}")


def parse_args():
    parser = argparse.ArgumentParser(description='HID-MuseFormer H800 è®­ç»ƒ')

    # æ•°æ®
    parser.add_argument('--data_dir', type=str, required=True, help='é¢„å¤„ç†æ•°æ®ç›®å½•')
    parser.add_argument('--val_split', type=float, default=0.05, help='éªŒè¯é›†æ¯”ä¾‹')
    parser.add_argument('--max_seq_len', type=int, default=24576, help='æœ€å¤§åºåˆ—é•¿åº¦ (H800: 24K+)')
    parser.add_argument('--max_samples', type=int, default=None, help='é™åˆ¶åŠ è½½æ ·æœ¬æ•°ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰')

    # æ¨¡å‹
    parser.add_argument('--model_size', type=str, default='base',
                        choices=['small', 'base', 'large', 'xlarge'], help='æ¨¡å‹å¤§å°')
    parser.add_argument('--max_bars', type=int, default=2048,
                        help='æœ€å¤§ bar æ•°é‡ (é»˜è®¤ 2048ï¼Œè¦†ç›– 99.8%% æ ·æœ¬)')
    # æ³¨ï¼šå·²ç§»é™¤ --attention_modeï¼Œç»Ÿä¸€ä½¿ç”¨ FlexAttention (PyTorch 2.5+)

    # è®­ç»ƒ
    parser.add_argument('--epochs', type=int, default=50, help='è®­ç»ƒ epochs')
    parser.add_argument('--batch_size', type=int, default=8, help='æ‰¹å¤§å° (per GPU)')
    parser.add_argument('--gradient_accumulation_steps', type=int, default=4, help='æ¢¯åº¦ç´¯ç§¯æ­¥æ•°')
    parser.add_argument('--learning_rate', type=float, default=1e-4, help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=0.1, help='æƒé‡è¡°å‡')
    parser.add_argument('--warmup_steps', type=int, default=2000, help='é¢„çƒ­æ­¥æ•°')
    parser.add_argument('--max_grad_norm', type=float, default=1.0, help='æ¢¯åº¦è£å‰ª')

    # H800 ä¼˜åŒ–
    parser.add_argument('--bf16', action='store_true', default=True, help='ä½¿ç”¨ BF16 (æ¨è)')
    parser.add_argument('--fp16', action='store_true', help='ä½¿ç”¨ FP16')
    parser.add_argument('--gradient_checkpointing', action='store_true', default=True, help='ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹')
    parser.add_argument('--compile', action='store_true', help='ä½¿ç”¨ torch.compile')

    # è¾“å‡º
    parser.add_argument('--output_dir', type=str, default='./outputs_h800', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--log_interval', type=int, default=50, help='æ—¥å¿—é—´éš”')
    parser.add_argument('--save_interval', type=int, default=2000, help='ä¿å­˜é—´éš”')

    # å…¶ä»–
    parser.add_argument('--num_workers', type=int, default=8, help='æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--resume', type=str, default=None, help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')

    # WandB
    parser.add_argument('--use_wandb', action='store_true', help='ä½¿ç”¨ WandB è®°å½•')
    parser.add_argument('--wandb_project', type=str, default='hid-museformer-h800', help='WandB é¡¹ç›®å')
    parser.add_argument('--run_name', type=str, default=None, help='è¿è¡Œåç§°')

    return parser.parse_args()


def main():
    args = parse_args()

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(args.seed)

    # æ£€æµ‹æ··åˆç²¾åº¦å¯ç”¨æ€§
    if args.bf16:
        if torch.cuda.is_available() and torch.cuda.is_bf16_supported():
            pass  # BF16 å¯ç”¨
        else:
            print("[Warning] BF16 ä¸æ”¯æŒ (éœ€è¦ Ampere+ GPU)ï¼Œå›é€€åˆ° FP32")
            args.bf16 = False
    if args.fp16 and args.bf16:
        print("[Warning] åŒæ—¶æŒ‡å®šäº† --fp16 å’Œ --bf16ï¼Œä¼˜å…ˆä½¿ç”¨ FP16")
        args.bf16 = False

    # åˆ›å»º tokenizer
    tokenizer = HIDTokenizerV2()

    # åŠ è½½é¢„å¤„ç†æ•°æ®é›†
    print("åŠ è½½é¢„å¤„ç†æ•°æ®é›†...")
    full_dataset = PreprocessedDataset(
        args.data_dir,
        max_seq_len=args.max_seq_len,
        max_bars=args.max_bars,
        max_samples=args.max_samples,  # ç”¨äºå¿«é€Ÿæµ‹è¯•
    )
    print(f"max_bars={args.max_bars} (è¶…è¿‡æ­¤å€¼çš„æ ·æœ¬å°†è¢«è·³è¿‡)")

    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    total_size = len(full_dataset)
    val_size = int(total_size * args.val_split)
    train_size = total_size - val_size

    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset,
        [train_size, val_size],
        generator=torch.Generator().manual_seed(args.seed)
    )

    print(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")

    # åˆ›å»ºæ¨¡å‹ (FlexAttention)
    print(f"\nåˆ›å»ºæ¨¡å‹ (size={args.model_size}, max_bars={args.max_bars}, attention=FlexAttention)...")
    model = create_model(
        vocab_size=tokenizer.vocab_size,
        model_size=args.model_size,
        max_seq_len=args.max_seq_len,
        max_bars=args.max_bars,
        chord_start_id=tokenizer.chord_start_id,
        chord_end_id=tokenizer.chord_end_id,
    )

    total_params = sum(p.numel() for p in model.parameters())
    print(f"æ¨¡å‹å‚æ•°é‡: {total_params / 1e6:.2f}M")

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = H800Trainer(model, train_dataset, val_dataset, args)

    # æ¢å¤è®­ç»ƒ
    if args.resume:
        trainer.load_checkpoint(args.resume)

    # å¼€å§‹è®­ç»ƒ
    try:
        trainer.train()
    finally:
        cleanup_distributed()


if __name__ == '__main__':
    main()
